{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jiS969e8lPuv"
   },
   "source": [
    "**Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OJE8wMYsk37O"
   },
   "outputs": [],
   "source": [
    "# Data manipulation\n",
    "import numpy as np         # Fundamental package for numerical computing\n",
    "import pandas as pd        # Data manipulation and analysis\n",
    "\n",
    "# File and system operations\n",
    "import os                  # Operating system operations\n",
    "import pickle              # Serialization of Python objects\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt  # Creating visualizations\n",
    "import seaborn as sns            # Statistical data visualization\n",
    "\n",
    "# Machine learning and deep learning\n",
    "import torch               # Deep learning framework\n",
    "import torch.nn as nn      # Neural network modules\n",
    "import torch.nn.functional as F  # Neural network functional operations\n",
    "import torch.optim as optim     # Optimization algorithms\n",
    "from torch.utils.data import DataLoader, SubsetRandomSampler, TensorDataset, random_split, ConcatDataset  # Data handling\n",
    "\n",
    "# Computer vision\n",
    "import torchvision         # Computer vision library\n",
    "import torchvision.transforms as transforms  # Image transformations\n",
    "import torchvision.datasets as datasets      # Standard datasets\n",
    "\n",
    "# Model summary\n",
    "from torchsummary import summary  # Summarizing PyTorch models\n",
    "\n",
    "# Metrics and model selection\n",
    "from sklearn.metrics import confusion_matrix  # Confusion matrix\n",
    "from sklearn.model_selection import KFold      # k-fold cross-validation\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8oKfoImmmhue"
   },
   "source": [
    "**Load Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OO4Fa2vInDQq"
   },
   "outputs": [],
   "source": [
    "#Access files\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c7yWOmh1oGFK"
   },
   "outputs": [],
   "source": [
    "# Paths to training and test folders\n",
    "train_folder_path = '/content/drive/.../train'\n",
    "test_folder_path = '/content/drive/M.../test'##\n",
    "\n",
    "batch_size   = 32\n",
    "num_epochs   = 15\n",
    "k_folds      = 5\n",
    "lr           = 1e-3\n",
    "momentum     = 0.9\n",
    "weight_decay = 1e-3\n",
    "        \n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qqVjGOM5oPUY"
   },
   "source": [
    "**Data Preprocessing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "blok8hEQmkQ9"
   },
   "outputs": [],
   "source": [
    "# %% [4] Transforms & Datasets\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.ColorJitter(0.2,0.2,0.2,0.2),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.485,0.456,0.406),(0.229,0.224,0.225))\n",
    "])\n",
    "valid_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.485,0.456,0.406),(0.229,0.224,0.225))\n",
    "])\n",
    "\n",
    "# train_set used for cross-validation; test_set held out for final evaluation\n",
    "train_set = datasets.ImageFolder(train_folder_path, transform=train_transform)\n",
    "test_set  = datasets.ImageFolder(test_folder_path,  transform=valid_transform)\n",
    "\n",
    "classes = train_set.classes\n",
    "print(\"Classes:\", classes)\n",
    "\n",
    "# Extract targets array for StratifiedKFold\n",
    "targets = np.array([sample[1] for sample in train_set.samples])\n",
    "\n",
    "skf = StratifiedKFold(n_splits=k_folds, shuffle=True, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, loader, criterion, optimizer):\n",
    "    model.train()\n",
    "    running_loss, correct = 0.0, 0\n",
    "    for imgs, labels in loader:\n",
    "        imgs, labels = imgs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(imgs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item() * imgs.size(0)\n",
    "        correct      += (outputs.argmax(1) == labels).sum().item()\n",
    "    avg_loss = running_loss / len(loader.sampler)\n",
    "    avg_acc  = correct      / len(loader.sampler) * 100\n",
    "    return avg_loss, avg_acc\n",
    "\n",
    "def valid_epoch(model, loader, criterion):\n",
    "    model.eval()\n",
    "    running_loss, correct = 0.0, 0\n",
    "    with torch.no_grad():\n",
    "        for imgs, labels in loader:\n",
    "            imgs, labels = imgs.to(device), labels.to(device)\n",
    "            outputs = model(imgs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            running_loss += loss.item() * imgs.size(0)\n",
    "            correct      += (outputs.argmax(1) == labels).sum().item()\n",
    "    avg_loss = running_loss / len(loader.sampler)\n",
    "    avg_acc  = correct      / len(loader.sampler) * 100\n",
    "    return avg_loss, avg_acc\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k1E6iO8NoSya"
   },
   "source": [
    "**Model Training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ke_uiOmaqDtU"
   },
   "outputs": [],
   "source": [
    "# %% [6] Cross-Validation + Fine-Tuned AlexNet\n",
    "fold_results = {}\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(skf.split(np.arange(len(train_set)), targets), 1):\n",
    "    print(f\"\\n--- Fold {fold}/{k_folds} ---\")\n",
    "\n",
    "    # Samplers & Loaders\n",
    "    train_sampler = SubsetRandomSampler(train_idx)\n",
    "    val_sampler   = SubsetRandomSampler(val_idx)\n",
    "\n",
    "    train_loader = DataLoader(train_set, batch_size=batch_size, sampler=train_sampler, num_workers=2)\n",
    "    val_loader   = DataLoader(train_set, batch_size=batch_size, sampler=val_sampler,   num_workers=2)\n",
    "\n",
    "    # Load pretrained AlexNet & freeze features\n",
    "    model = models.alexnet(pretrained=True)\n",
    "    for param in model.features.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "    # Replace classifier head\n",
    "    num_ftrs = model.classifier[6].in_features\n",
    "    model.classifier[6] = nn.Linear(num_ftrs, len(classes))\n",
    "    nn.init.xavier_uniform_(model.classifier[6].weight)\n",
    "    model = model.to(device)\n",
    "\n",
    "    # Show summary once (on first fold)\n",
    "    if fold==1:\n",
    "        summary(model, (3,224,224))\n",
    "\n",
    "\n",
    "\n",
    "    # Loss & Optimizer (only classifier params)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.SGD(filter(lambda p: p.requires_grad, model.parameters()),\n",
    "                          lr=lr, momentum=momentum, weight_decay=weight_decay)\n",
    "\n",
    "    # Train/Validate\n",
    "    history = {'train_loss':[], 'train_acc':[], 'val_loss':[], 'val_acc':[]}\n",
    "    for epoch in tqdm(range(1, num_epochs+1), desc=f\"Fold {fold}\"):\n",
    "        tr_loss, tr_acc = train_epoch(model, train_loader, criterion, optimizer)\n",
    "        val_loss, val_acc = valid_epoch(model, val_loader, criterion)\n",
    "\n",
    "        history['train_loss'].append(tr_loss)\n",
    "        history['train_acc'].append(tr_acc)\n",
    "        history['val_loss'].append(val_loss)\n",
    "        history['val_acc'].append(val_acc)\n",
    "\n",
    "        print(f\"Epoch {epoch}/{num_epochs} â€” \"\n",
    "              f\"Train: {tr_loss:.4f}, {tr_acc:5.2f}% | \"\n",
    "              f\"Val:   {val_loss:.4f}, {val_acc:5.2f}%\")\n",
    "\n",
    "    fold_results[f\"fold{fold}\"] = history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nmZGKT6wqJ5g"
   },
   "outputs": [],
   "source": [
    "# Save the model to a file\n",
    "torch.save(model.state_dict(), 'model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ATWVjFfKqU_X"
   },
   "outputs": [],
   "source": [
    "# Visualize cross-validation results\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot loss curves for each fold\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "for fold, history in fold_results.items():\n",
    "    plt.plot(history['train_loss'], label=f\"{fold} Train Loss\")\n",
    "    plt.plot(history['val_loss'],   label=f\"{fold} Val Loss\")\n",
    "\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Training vs. Validation Loss per Fold\")\n",
    "plt.legend(fontsize='small')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Plot accuracy curves for each fold\n",
    "plt.figure(figsize=(10,5))\n",
    "for fold, history in fold_results.items():\n",
    "    plt.plot(history['train_acc'], label=f\"{fold} Train Acc\")\n",
    "    plt.plot(history['val_acc'],   label=f\"{fold} Val Acc\")\n",
    "\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy (%)\")\n",
    "plt.title(\"Training vs. Validation Accuracy per Fold\")\n",
    "plt.legend(fontsize='small')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "x0xS-6TVqwRU"
   },
   "outputs": [],
   "source": [
    "\n",
    "# %% [X+2] Average Performance Across Folds\n",
    "# Stack histories into arrays\n",
    "train_losses = np.stack([h['train_loss'] for h in fold_results.values()], axis=0)\n",
    "val_losses   = np.stack([h['val_loss']   for h in fold_results.values()], axis=0)\n",
    "train_accs   = np.stack([h['train_acc'] for h in fold_results.values()], axis=0)\n",
    "val_accs     = np.stack([h['val_acc']   for h in fold_results.values()], axis=0)\n",
    "\n",
    "# Compute epoch-wise means\n",
    "train_loss_avg = train_losses.mean(axis=0)\n",
    "val_loss_avg   = val_losses.mean(axis=0)\n",
    "train_acc_avg  = train_accs.mean(axis=0)\n",
    "val_acc_avg    = val_accs.mean(axis=0)\n",
    "\n",
    "# Plot averaged loss\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.plot(train_loss_avg, label='Avg Train Loss')\n",
    "plt.plot(val_loss_avg,   label='Avg Val Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Average Loss Across Folds')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Plot averaged accuracy\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.plot(train_acc_avg, label='Avg Train Acc')\n",
    "plt.plot(val_acc_avg,   label='Avg Val Acc')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy (%)')\n",
    "plt.title('Average Accuracy Across Folds')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Print final-epoch averages\n",
    "print(f\"Final Avg Train Loss: {train_loss_avg[-1]:.4f}\")\n",
    "print(f\"Final Avg Val   Loss: {val_loss_avg[-1]:.4f}\")\n",
    "print(f\"Final Avg Train Acc : {train_acc_avg[-1]:.2f}%\")\n",
    "print(f\"Final Avg Val   Acc : {val_acc_avg[-1]:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2GBQV836rtOG"
   },
   "source": [
    "**MODEL EVALUATION**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jyqiajUyrX9z"
   },
   "outputs": [],
   "source": [
    "\n",
    "test_loader = DataLoader(test_set, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "\n",
    "# Build confusion matrix tensor\n",
    "cm_tensor = torch.zeros(len(classes), len(classes), dtype=torch.int64)\n",
    "\n",
    "correct, total = 0, 0\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for imgs, labels in test_loader:\n",
    "        imgs, labels = imgs.to(device), labels.to(device)\n",
    "        preds = model(imgs).argmax(dim=1)\n",
    "        correct += (preds == labels).sum().item()\n",
    "        total   += labels.size(0)\n",
    "        for t, p in zip(labels.view(-1), preds.view(-1)):\n",
    "            cm_tensor[t, p] += 1\n",
    "\n",
    "test_acc = correct / total * 100\n",
    "print(f\"\\nTest Accuracy: {test_acc:.2f}%\")\n",
    "print(\"Confusion Matrix (rows=true, cols=pred):\\n\", cm_tensor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bHJDrwd0r_Ew"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6, 5))\n",
    "sns.heatmap(cm_tensor.cpu().numpy(), annot=True, fmt='d',\n",
    "            xticklabels=classes, yticklabels=classes, cmap='Blues')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LwBIinbnr--C"
   },
   "outputs": [],
   "source": [
    "# %% [X+5] Compute Precision, Recall, F1-Score\n",
    "tp = cm_tensor[1,1].item()\n",
    "tn = cm_tensor[0,0].item()\n",
    "fp = cm_tensor[0,1].item()\n",
    "fn = cm_tensor[1,0].item()\n",
    "\n",
    "precision = tp / (tp + fp) if (tp + fp) > 0 else 0.0\n",
    "recall    = tp / (tp + fn) if (tp + fn) > 0 else 0.0\n",
    "f1_score  = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0.0\n",
    "\n",
    "metrics_df = pd.DataFrame({\n",
    "    'Accuracy': [test_acc],\n",
    "    'Precision': [precision * 100],\n",
    "    'Recall':    [recall    * 100],\n",
    "    'F1-Score':  [f1_score  * 100]\n",
    "}, index=['Overall'])\n",
    "\n",
    "print(\"\\nClassification Metrics:\")\n",
    "print(metrics_df.round(2))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
